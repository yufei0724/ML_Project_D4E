{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cc49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected task: CLASSIFICATION (classes=2)\n",
      "Feature count: 32 | Cat features: 22\n",
      "Done {'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 3} | F1=0.6874 ACC=0.6919 LogLoss=0.5757\n",
      "Done {'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 7} | F1=0.6888 ACC=0.6934 LogLoss=0.5750\n",
      "Done {'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 3} | F1=0.6881 ACC=0.6923 LogLoss=0.5747\n",
      "Done {'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7} | F1=0.6896 ACC=0.6939 LogLoss=0.5729\n",
      "Done {'depth': 8, 'learning_rate': 0.05, 'l2_leaf_reg': 3} | F1=0.6877 ACC=0.6919 LogLoss=0.5741\n",
      "Done {'depth': 8, 'learning_rate': 0.05, 'l2_leaf_reg': 7} | F1=0.6895 ACC=0.6939 LogLoss=0.5732\n",
      "Done {'depth': 8, 'learning_rate': 0.1, 'l2_leaf_reg': 3} | F1=0.6892 ACC=0.6932 LogLoss=0.5743\n",
      "Done {'depth': 8, 'learning_rate': 0.1, 'l2_leaf_reg': 7} | F1=0.6891 ACC=0.6930 LogLoss=0.5736\n",
      "Saved grid_results.csv\n",
      "BEST PARAMS: {'depth': 6, 'learning_rate': 0.1, 'l2_leaf_reg': 7.0}\n",
      "BEST CV: {'cv_f1_macro_mean': 0.689581973476848, 'cv_acc_mean': 0.6938816289014107, 'cv_logloss_mean': 0.5729156357367121}\n",
      "\n",
      "Confusion matrix:\n",
      "[[4049 1242]\n",
      " [1747 2972]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.70      0.77      0.73      5291\n",
      "           S       0.71      0.63      0.67      4719\n",
      "\n",
      "    accuracy                           0.70     10010\n",
      "   macro avg       0.70      0.70      0.70     10010\n",
      "weighted avg       0.70      0.70      0.70     10010\n",
      "\n",
      "\n",
      "Saved predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "DATA_DIR = \"Data\"   \n",
    "SEED = 66\n",
    "\n",
    "\n",
    "# I/O \n",
    "def must_exist(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "\n",
    "def read_csv(name: str) -> pd.DataFrame:\n",
    "    path = os.path.join(DATA_DIR, name)\n",
    "    must_exist(path)\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "def to_str_cols(df: pd.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(\"string\")\n",
    "\n",
    "\n",
    "#  Feature table \n",
    "def build_table(people, job, job_sec, pension, sport,\n",
    "                city_adm, city_pop, departments, regions) -> pd.DataFrame:\n",
    "    df = people.copy()\n",
    "\n",
    "    # flags\n",
    "    for name, sub in [\n",
    "        (\"has_employee_job\", job),\n",
    "        (\"has_job_security\", job_sec),\n",
    "        (\"has_pension\", pension),\n",
    "        (\"is_sport_member\", sport),\n",
    "    ]:\n",
    "        df[name] = df[\"UID\"].isin(sub[\"UID\"]).astype(int)\n",
    "\n",
    "    # merges\n",
    "    df = df.merge(job_sec, on=\"UID\", how=\"left\")\n",
    "    df = df.merge(job, on=\"UID\", how=\"left\")\n",
    "    df = df.merge(pension, on=\"UID\", how=\"left\")\n",
    "    df = df.merge(sport, on=\"UID\", how=\"left\")\n",
    "\n",
    "    # geographical merges\n",
    "    df = df.merge(city_adm, on=\"INSEE\", how=\"left\")\n",
    "    df = df.merge(city_pop, on=\"INSEE\", how=\"left\")\n",
    "    df = df.merge(departments, on=\"DEP\", how=\"left\")\n",
    "    df = df.merge(regions, on=\"Reg\", how=\"left\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# CatBoost helpers\n",
    "def make_cat_features(X: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    # 1) auto-detect object/string cols as categorical\n",
    "    cat_cols = [c for c in X.columns if (X[c].dtype == \"object\") or str(X[c].dtype).startswith(\"string\")]\n",
    "\n",
    "    # 2) some code columns to force as categorical\n",
    "    force_cat = [\"INSEE\", \"DEP\", \"Reg\", \"job_dep\", \"JOB_SECURITY\", \"Sports\"]\n",
    "    for c in force_cat:\n",
    "        if c in X.columns and c not in cat_cols:\n",
    "            cat_cols.append(c)\n",
    "\n",
    "    # CatBoost requires string type + fillna\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "        X_test[c] = X_test[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "    cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "    return cat_cols, cat_idx\n",
    "\n",
    "\n",
    "def grid_search_catboost(X, y, cat_idx, seed=66):\n",
    "    # 8 combinations\n",
    "    grid = []\n",
    "    for depth in [6, 8]:\n",
    "        for lr in [0.05, 0.1]:\n",
    "            for l2 in [3, 7]:\n",
    "                grid.append({\"depth\": depth, \"learning_rate\": lr, \"l2_leaf_reg\": l2})\n",
    "\n",
    "    classes = sorted(y.astype(str).unique().tolist())\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "    results = []\n",
    "    for g in grid:\n",
    "        accs, f1s, lls = [], [], []\n",
    "\n",
    "        for tr, va in cv.split(X, y):\n",
    "            train_pool = Pool(X.iloc[tr], y.iloc[tr], cat_features=cat_idx)\n",
    "            valid_pool = Pool(X.iloc[va], y.iloc[va], cat_features=cat_idx)\n",
    "\n",
    "            model = CatBoostClassifier(\n",
    "                loss_function=\"Logloss\",\n",
    "                iterations=500,        \n",
    "                od_type=\"Iter\",        # early stopping\n",
    "                od_wait=50,\n",
    "                random_seed=seed,\n",
    "                thread_count=-1,\n",
    "                verbose=False,\n",
    "                **g\n",
    "            )\n",
    "            model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "            pred = model.predict(valid_pool).astype(str).ravel()\n",
    "            proba = model.predict_proba(valid_pool)\n",
    "\n",
    "            y_true = y.iloc[va].astype(str).values\n",
    "            accs.append(accuracy_score(y_true, pred))\n",
    "            f1s.append(f1_score(y_true, pred, average=\"macro\"))\n",
    "            lls.append(log_loss(y_true, proba, labels=classes))\n",
    "\n",
    "        row = {\n",
    "            **g,\n",
    "            \"cv_acc_mean\": float(np.mean(accs)),\n",
    "            \"cv_f1_macro_mean\": float(np.mean(f1s)),\n",
    "            \"cv_logloss_mean\": float(np.mean(lls)),\n",
    "        }\n",
    "        results.append(row)\n",
    "        print(f\"Done {g} | F1={row['cv_f1_macro_mean']:.4f} ACC={row['cv_acc_mean']:.4f} LogLoss={row['cv_logloss_mean']:.4f}\")\n",
    "\n",
    "    res_df = pd.DataFrame(results).sort_values(\n",
    "        by=[\"cv_f1_macro_mean\", \"cv_logloss_mean\"],\n",
    "        ascending=[False, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    res_df.to_csv(\"grid_results.csv\", index=False)\n",
    "    print(\"Saved grid_results.csv\")\n",
    "\n",
    "    best = res_df.iloc[0].to_dict()\n",
    "    best_params = {\n",
    "        \"depth\": int(best[\"depth\"]),\n",
    "        \"learning_rate\": float(best[\"learning_rate\"]),\n",
    "        \"l2_leaf_reg\": float(best[\"l2_leaf_reg\"]),\n",
    "    }\n",
    "    print(\"BEST PARAMS:\", best_params)\n",
    "    print(\"BEST CV:\", {\n",
    "        \"cv_f1_macro_mean\": best[\"cv_f1_macro_mean\"],\n",
    "        \"cv_acc_mean\": best[\"cv_acc_mean\"],\n",
    "        \"cv_logloss_mean\": best[\"cv_logloss_mean\"],\n",
    "    })\n",
    "    return best_params, res_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load \n",
    "    learn = read_csv(\"learn_dataset.csv\")\n",
    "    test = read_csv(\"test_dataset.csv\")\n",
    "\n",
    "    learn_job = read_csv(\"learn_dataset_job.csv\")\n",
    "    test_job = read_csv(\"test_dataset_job.csv\")\n",
    "\n",
    "    learn_js = read_csv(\"learn_dataset_JOB_SECURITY.csv\")\n",
    "    test_js = read_csv(\"test_dataset_JOB_SECURITY.csv\")\n",
    "\n",
    "    learn_pension = read_csv(\"learn_dataset_retired_pension.csv\")\n",
    "    test_pension = read_csv(\"test_dataset_retired_pension.csv\")\n",
    "\n",
    "    learn_sport = read_csv(\"learn_dataset_sport.csv\")\n",
    "    test_sport = read_csv(\"test_dataset_sport.csv\")\n",
    "\n",
    "    city_adm = read_csv(\"city_adm.csv\")\n",
    "    city_pop = read_csv(\"city_pop.csv\")\n",
    "    departments = read_csv(\"departments.csv\")\n",
    "    regions = read_csv(\"regions.csv\")\n",
    "\n",
    "    # to string\n",
    "    to_str_cols(learn, [\"INSEE\"])\n",
    "    to_str_cols(test, [\"INSEE\"])\n",
    "    to_str_cols(city_adm, [\"INSEE\", \"DEP\"])\n",
    "    to_str_cols(city_pop, [\"INSEE\"])\n",
    "    to_str_cols(departments, [\"DEP\", \"Reg\"])\n",
    "    to_str_cols(regions, [\"Reg\"])\n",
    "    to_str_cols(learn_job, [\"job_dep\"])\n",
    "    to_str_cols(test_job, [\"job_dep\"])\n",
    "    to_str_cols(learn_js, [\"JOB_SECURITY\"])\n",
    "    to_str_cols(test_js, [\"JOB_SECURITY\"])\n",
    "    to_str_cols(learn_sport, [\"Sports\"])\n",
    "    to_str_cols(test_sport, [\"Sports\"])\n",
    "\n",
    "    # merge all\n",
    "    train_df = build_table(learn, learn_job, learn_js, learn_pension, learn_sport,\n",
    "                           city_adm, city_pop, departments, regions)\n",
    "    test_df = build_table(test, test_job, test_js, test_pension, test_sport,\n",
    "                          city_adm, city_pop, departments, regions)\n",
    "\n",
    "    # X/y\n",
    "    y = train_df[\"target\"].astype(\"string\").fillna(\"__MISSING_TARGET__\")\n",
    "    X = train_df.drop(columns=[\"target\"]).copy()\n",
    "\n",
    "    test_uid = test_df[\"UID\"].copy()\n",
    "    X_test = test_df.copy()\n",
    "\n",
    "    # UID drop\n",
    "    X.drop(columns=[\"UID\"], inplace=True)\n",
    "    X_test.drop(columns=[\"UID\"], inplace=True)\n",
    "\n",
    "    # category features processing\n",
    "    cat_cols, cat_idx = make_cat_features(X, X_test)\n",
    "\n",
    "    print(f\"Detected task: CLASSIFICATION (classes={y.nunique()})\")\n",
    "    print(f\"Feature count: {X.shape[1]} | Cat features: {len(cat_cols)}\")\n",
    "\n",
    "    #  grid search (3-fold)\n",
    "    best_params, _ = grid_search_catboost(X, y, cat_idx, seed=SEED)\n",
    "\n",
    "    # other fixed training params\n",
    "    base_params = dict(\n",
    "        loss_function=\"Logloss\",\n",
    "        iterations=500,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=50,\n",
    "        random_seed=SEED,\n",
    "        thread_count=-1,\n",
    "        verbose=False,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    #  confusion matrix (holdout 20%) \n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=66, stratify=y\n",
    "    )\n",
    "    tr_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n",
    "    va_pool = Pool(X_va, y_va, cat_features=cat_idx)\n",
    "\n",
    "    cm_model = CatBoostClassifier(**base_params)\n",
    "    cm_model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "\n",
    "    pred_va = cm_model.predict(va_pool).astype(str).ravel()\n",
    "    y_va_str = y_va.astype(str).values\n",
    "\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_va_str, pred_va))\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_va_str, pred_va))\n",
    "\n",
    "    # final train + predict \n",
    "    full_pool = Pool(X, y, cat_features=cat_idx)\n",
    "    test_pool = Pool(X_test, cat_features=cat_idx)\n",
    "\n",
    "    final_model = CatBoostClassifier(**base_params)\n",
    "    final_model.fit(full_pool)\n",
    "\n",
    "    pred_test = final_model.predict(test_pool).astype(str).ravel()\n",
    "    out = pd.DataFrame({\"UID\": test_uid, \"target\": pred_test})\n",
    "    out.to_csv(\"predictions.csv\", index=False)\n",
    "    print(\"\\nSaved predictions.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
